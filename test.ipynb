{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (graph_builder.py, line 84)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2961\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-55-04eebca15882>\"\u001b[0m, line \u001b[1;32m9\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    reload(gb)\n",
      "  File \u001b[1;32m\"/usr/lib/python3.5/importlib/__init__.py\"\u001b[0m, line \u001b[1;32m166\u001b[0m, in \u001b[1;35mreload\u001b[0m\n    _bootstrap._exec(spec, module)\n",
      "  File \u001b[1;32m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[1;32m626\u001b[0m, in \u001b[1;35m_exec\u001b[0m\n",
      "  File \u001b[1;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[1;32m661\u001b[0m, in \u001b[1;35mexec_module\u001b[0m\n",
      "  File \u001b[1;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[1;32m767\u001b[0m, in \u001b[1;35mget_code\u001b[0m\n",
      "  File \u001b[1;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[1;32m727\u001b[0m, in \u001b[1;35msource_to_code\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<frozen importlib._bootstrap>\"\u001b[0;36m, line \u001b[0;32m222\u001b[0;36m, in \u001b[0;35m_call_with_frames_removed\u001b[0;36m\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/deep09/project_vlad1/simulation/simulation_builder/graph_builder.py\"\u001b[0;36m, line \u001b[0;32m84\u001b[0m\n\u001b[0;31m    self._train_writer_dict = {}\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from importlib import reload\n",
    "from simulation.simulation_builder import graph_builder as gb\n",
    "from simulation.architectures.mnist_architectures import cnn_mnist_architecture\n",
    "from tensorflow.python.client import device_lib\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "reload(gb)\n",
    "g = gb.GraphBuilder(cnn_mnist_architecture,\n",
    "                   learning_rate=0.01,\n",
    "                   noise_list=[0.9, 0.8, 0.7, 0.6],\n",
    "                   noise_type='dropout',\n",
    "                   name='test')\n",
    "#device_lib.list_local_devices()\n",
    "\n",
    "def stdwrite(buff):\n",
    "    sys.stdout.write('\\r' + buff)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting simulation/data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting simulation/data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting simulation/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting simulation/data/mnist/t10k-labels-idx1-ubyte.gz\n",
      " ,0.07211064 ,0.076414496 ,0.07123181 ,0.0780832756"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "with g._graph.as_default():\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    data_path = 'simulation/data/mnist/'\n",
    "    mnist = input_data.read_data_sets(data_path)\n",
    "    test_feed_dict = g.create_feed_dict(mnist.test.images,\n",
    "                                       mnist.test.labels,\n",
    "                                       test=True)\n",
    "    step = 0\n",
    "    n_iters = n_iters = mnist.train.num_examples // batch_size\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(g.variable_initializer)\n",
    "        for epoch in range(10):\n",
    "            for it in range(n_iters):\n",
    "                step += 1\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "\n",
    "                evaluated = sess.run(g.get_train_ops(),\n",
    "                                    feed_dict=g.create_feed_dict(X_batch,\n",
    "                                                                y_batch))\n",
    "                if it % 200 == 0:\n",
    "                    evaluated = sess.run(g.get_train_ops(test=True),\n",
    "                                        feed_dict=test_feed_dict)\n",
    "                    loss = g.extract_evaluated_tensors(evaluated, 'loss')\n",
    "                    buff = ''\n",
    "                    for l in loss:\n",
    "                        buff = buff + ' ,' + str(l)\n",
    "                    stdwrite(buff)\n",
    "                    #g.update_noise_vals(evaluated)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation.architectures.mnist_architectures import nn_mnist_architecture\n",
    "reload(gb)\n",
    "\n",
    "g = gb.GraphBuilder(nn_mnist_architecture,\n",
    "                   learning_rate=0.01,\n",
    "                   noise_list=[0.001, 0.003, 0.004, 0.009],\n",
    "                   noise_type='random_normal',\n",
    "                   name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting simulation/data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting simulation/data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting simulation/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting simulation/data/mnist/t10k-labels-idx1-ubyte.gz\n",
      " ,2.583502 ,2.5000777 ,2.6621485 ,2.646446[(2.5000777, 1), (2.583502, 0), (2.646446, 3), (2.6621485, 2)]\n",
      "{\n",
      "  \"0\": 0.001,\n",
      "  \"1\": 0.003,\n",
      "  \"2\": 0.004,\n",
      "  \"3\": 0.009\n",
      "}\n",
      "{\n",
      "  \"0\": 0.003,\n",
      "  \"1\": 0.001,\n",
      "  \"2\": 0.009,\n",
      "  \"3\": 0.004\n",
      "}\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2969: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "with g._graph.as_default():\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    data_path = 'simulation/data/mnist/'\n",
    "    mnist = input_data.read_data_sets(data_path)\n",
    "    test_feed_dict = g.create_feed_dict(mnist.test.images,\n",
    "                                       mnist.test.labels,\n",
    "                                       test=True)\n",
    "    step = 0\n",
    "    n_iters = n_iters = mnist.train.num_examples // batch_size\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(g.variable_initializer)\n",
    "        for epoch in range(10):\n",
    "            for it in range(n_iters):\n",
    "                step += 1\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "\n",
    "                evaluated = sess.run(g.get_train_ops(),\n",
    "                                    feed_dict=g.create_feed_dict(X_batch,\n",
    "                                                                y_batch))\n",
    "                if it % 200 == 0:\n",
    "                    evaluated = sess.run(g.get_train_ops(test=True),\n",
    "                                        feed_dict=test_feed_dict)\n",
    "                    loss = g.extract_evaluated_tensors(evaluated, 'loss')\n",
    "                    buff = ''\n",
    "                    for l in loss:\n",
    "                        buff = buff + ' ,' + str(l)\n",
    "                    stdwrite(buff)\n",
    "                    g.update_noise_vals(evaluated)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    with tf.name_scope('Loss'):\n",
    "        with tf.device('/gpu:0'):\n",
    "            cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                                            logits=logits)\n",
    "        with tf.device('/cpu:0'):\n",
    "            loss = tf.reduce_mean(cross_entropy, name='loss')\n",
    "    with tf.name_scope('Accuracy'):\n",
    "        with tf.device('/cpu:0'):\n",
    "            y_pred = tf.nn.in_top_k(predictions=logits, targets=y, k=1)\n",
    "            accuracy = tf.reduce_mean(tf.cast(x=y_pred, dtype=tf.float32),\n",
    "                                     name='accuracy')\n",
    "    with tf.name_scope('Optimizer'):\n",
    "        with tf.device('/gpu:0'):\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "            train_op = optimizer.minimize(loss)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print(train_op.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation.simulation_builder import optimizers as o\n",
    "opt = o.GDOptimizer(0.01, 0, [0.01, 0.02])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = Child1()\n",
    "print(c1.var)\n",
    "c2 = Child2()\n",
    "print(c2.var)\n",
    "print('')\n",
    "c1.change()\n",
    "c2.change()\n",
    "print(c1.var, c2.var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
