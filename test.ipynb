{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from importlib import reload\n",
    "from simulation.simulation_builder import graph_builder as gb\n",
    "from simulation.architectures.mnist_architectures import cnn_mnist_architecture\n",
    "from tensorflow.python.client import device_lib\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "reload(gb)\n",
    "g = gb.GraphBuilder(cnn_mnist_architecture,\n",
    "                   learning_rate=0.01,\n",
    "                   noise_list=[0.9, 0.8, 0.7, 0.6],\n",
    "                   noise_type='dropout',\n",
    "                   name='test')\n",
    "#device_lib.list_local_devices()\n",
    "\n",
    "def stdwrite(buff):\n",
    "    sys.stdout.write('\\r' + buff)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "with g._graph.as_default():\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    data_path = 'simulation/data/mnist/'\n",
    "    mnist = input_data.read_data_sets(data_path)\n",
    "    test_feed_dict = g.create_feed_dict(mnist.test.images,\n",
    "                                       mnist.test.labels,\n",
    "                                       test=True)\n",
    "    step = 0\n",
    "    n_iters = n_iters = mnist.train.num_examples // batch_size\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(g.variable_initializer)\n",
    "        for epoch in range(10):\n",
    "            for it in range(n_iters):\n",
    "                step += 1\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "\n",
    "                evaluated = sess.run(g.get_train_ops(),\n",
    "                                    feed_dict=g.create_feed_dict(X_batch,\n",
    "                                                                y_batch))\n",
    "                if it % 200 == 0:\n",
    "                    evaluated = sess.run(g.get_train_ops(test=True),\n",
    "                                        feed_dict=test_feed_dict)\n",
    "                    loss = g.extract_evaluated_tensors(evaluated, 'loss')\n",
    "                    buff = ''\n",
    "                    for l in loss:\n",
    "                        buff = buff + ' ,' + str(l)\n",
    "                    stdwrite(buff)\n",
    "                    #g.update_noise_vals(evaluated)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from simulation.simulation_builder import graph_builder as gb\n",
    "\n",
    "from simulation.architectures.mnist_architectures import nn_mnist_architecture\n",
    "reload(gb)\n",
    "print(1)\n",
    "g = gb.GraphBuilder(nn_mnist_architecture,\n",
    "                   learning_rate=0.01,\n",
    "                   noise_list=[0.001, 0.003, 0.004, 0.009],\n",
    "                   noise_type='random_normal',\n",
    "                   name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "with g._graph.as_default():\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    data_path = 'simulation/data/mnist/'\n",
    "    mnist = input_data.read_data_sets(data_path)\n",
    "    test_feed_dict = g.create_feed_dict(mnist.test.images,\n",
    "                                       mnist.test.labels,\n",
    "                                       test=True)\n",
    "    step = 0\n",
    "    n_iters = n_iters = mnist.train.num_examples // batch_size\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(g.variable_initializer)\n",
    "        for epoch in range(10):\n",
    "            for it in range(n_iters):\n",
    "                step += 1\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "\n",
    "                evaluated = sess.run(g.get_train_ops(),\n",
    "                                    feed_dict=g.create_feed_dict(X_batch,\n",
    "                                                                y_batch))\n",
    "                if it % 200 == 0:\n",
    "                    evaluated = sess.run(g.get_train_ops(test=True),\n",
    "                                        feed_dict=test_feed_dict)\n",
    "                    loss = g.extract_evaluated_tensors(evaluated, 'loss')\n",
    "                    buff = ''\n",
    "                    for l in loss:\n",
    "                        buff = buff + ' ,' + str(l)\n",
    "                    stdwrite(buff)\n",
    "                    g.update_noise_vals(evaluated)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    with tf.name_scope('Loss'):\n",
    "        with tf.device('/gpu:0'):\n",
    "            cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                                            logits=logits)\n",
    "        with tf.device('/cpu:0'):\n",
    "            loss = tf.reduce_mean(cross_entropy, name='loss')\n",
    "    with tf.name_scope('Accuracy'):\n",
    "        with tf.device('/cpu:0'):\n",
    "            y_pred = tf.nn.in_top_k(predictions=logits, targets=y, k=1)\n",
    "            accuracy = tf.reduce_mean(tf.cast(x=y_pred, dtype=tf.float32),\n",
    "                                     name='accuracy')\n",
    "    with tf.name_scope('Optimizer'):\n",
    "        with tf.device('/gpu:0'):\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "            train_op = optimizer.minimize(loss)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print(train_op.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulation.simulation_builder import optimizers as o\n",
    "opt = o.GDOptimizer(0.01, 0, [0.01, 0.02])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
